experiment: initial-experiments
run: initial_experiment
conditions: [ ]
batch_size: 8
epochs: 100
train_dataset_cfg:
  skip_conditioning: true
test_dataset_cfg:
  skip_conditioning: true
model_cfg:
  model_type: gpt2-lm
  model_kws:
    n_embd: 512
    n_layer: 6
    n_head: 8
optimizer_cfg:
  optimizer_type: adam
  optimizer_kws:
    #    lr: 10.0e-4
    lr: 2.0e-6
scheduler_cfg:
  scheduler_type: null
  scheduler_kws: { }
checkpoint_cfg:
  save_checkpoints: True
  load_checkpoints: True
  checkpoint_after_n_epochs: 10
tokenizer_cfg:
  tokenizer_str: REMI
  training_method: BPE
  tokenizer_kws: { }
mlflow_cfg:
  use: True
  port: 5000